@article{tas-survey,
  title = {Temporal action segmentation: An analysis of modern techniques},
  author = {Ding, Guodong and Sener, Fadime and Yao, Angela},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2023},
  publisher = {IEEE}
}

% NOTE: have been used as inspiration for the approach schema
@article{v7labs2025,
  author = {V7 Labs},
  title = {Video Segmentation Guide},
  year = {2025},
  url = {v7labs.com/blog/video-segmentation-guide},
}

@article{assembly101-dataset,
  title = {Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities},
  author = {F. Sener and D. Chatterjee and D. Shelepov and K. He and D. Singhania and R. Wang and A. Yao},
  journal = {CVPR 2022},
}

@article{gtea-dataset,
  title = {TricorNet: A Hybrid Temporal Convolutional and Recurrent Network for Video Action Segmentation},
  author = {Li Ding and Chenliang Xu},
  booktitle={ICLR},
  year = {2018},
}

@article{kinetics-400-dataset,
  title = {The Kinetics Human Action Video Dataset},
  author = {Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal = {arXiv preprint arXiv:1705.06950},
  year = {2017}
}

@article{kinetics-700-dataset,
  title = {A Short Note on the Kinetics-700 Human Action Dataset},
  author = {Carreira, Joao and Noland, Eric and Hillier, Chloe and Zisserman, Andrew},
  journal = {arXiv preprint arXiv:1907.06987},
  year = {2019}
}

@article{kinetics-600-dataset,
  title={A Short Note about Kinetics-600},
  author = {Carreira, João and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  journal = {arXiv preprint arXiv:1808.01340},
  year = {2018},
  url = {https://arxiv.org/abs/1808.01340}
}

@inproceedings{howto100m-dataset,
  title = {How{T}o100{M}: {L}earning a {T}ext-{V}ideo {E}mbedding by {W}atching {H}undred {M}illion {N}arrated {V}ideo {C}lips},
  author = {Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle = {ICCV},
  year = {2019},
}

@article{something-something-dataset,
  title = {The 'something something' video database for learning and evaluating visual common sense},
  author = {Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzy{\'n}ska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and Hoppe, Florian and Thurau, Christian and Bax, Ingo and Memisevic, Roland},
  journal = {arXiv preprint arXiv:1706.04261},
  year = {2017},
  url = {https://arxiv.org/abs/1706.04261}
}

@article{resnet-3d,
  author = {Kensho Hara and Hirokatsu Kataoka and Yutaka Satoh},
  title = {Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?},
  journal = {arXiv preprint},
  volume = {arXiv:1711.09577},
  year = {2017},
}

@article{i3d,
  title={Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset},
  author={João Carreira and Andrew Zisserman},
  journal={arXiv preprint arXiv:1705.07750},
  year={2018},
  url={https://arxiv.org/abs/1705.07750}
}

@misc{dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timothée and Moutakanni, Theo and Vo, Huy V. and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Howes, Russell and Huang, Po-Yao and Xu, Hu and Sharma, Vasu and Li, Shang-Wen and Galuba, Wojciech and Rabbat, Mike and Assran, Mido and Ballas, Nicolas and Synnaeve, Gabriel and Misra, Ishan and Jegou, Herve and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
  journal={arXiv:2304.07193},
  year={2023}
}

@article{x3d,
  title={X3D: Expanding architectures for efficient video recognition},
  author={Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2004.04730},
  year={2020},
  url={https://arxiv.org/abs/2004.04730}
}

@article{vivit,
       author = {{Arnab}, Anurag and {Dehghani}, Mostafa and {Heigold}, Georg and {Sun}, Chen and {Lu{\v{c}}i{\'c}}, Mario and {Schmid}, Cordelia},
        title = "{ViViT: A Video Vision Transformer}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2021,
        month = mar,
          eid = {arXiv:2103.15691},
        pages = {arXiv:2103.15691},
          doi = {10.48550/arXiv.2103.15691},
archivePrefix = {arXiv},
       eprint = {2103.15691},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv210315691A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{slowfast,
  author =       {Haoqi Fan and Yanghao Li and Bo Xiong and Wan-Yen Lo and
                  Christoph Feichtenhofer},
  title =        {PySlowFast},
  howpublished = {\url{https://github.com/facebookresearch/slowfast}},
  year =         {2020}
}

@article{s3d,
       author = {{Xie}, Saining and {Sun}, Chen and {Huang}, Jonathan and {Tu}, Zhuowen and {Murphy}, Kevin},
        title = "{Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2017,
        month = dec,
          eid = {arXiv:1712.04851},
        pages = {arXiv:1712.04851},
          doi = {10.48550/arXiv.1712.04851},
archivePrefix = {arXiv},
       eprint = {1712.04851},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171204851X},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{yolo,
       author = {{Redmon}, Joseph and {Divvala}, Santosh and {Girshick}, Ross and {Farhadi}, Ali},
        title = "{You Only Look Once: Unified, Real-Time Object Detection}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2015,
        month = jun,
          eid = {arXiv:1506.02640},
        pages = {arXiv:1506.02640},
          doi = {10.48550/arXiv.1506.02640},
archivePrefix = {arXiv},
       eprint = {1506.02640},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv150602640R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{video-action-recognition-study,
       author = {{Zhu}, Yi and {Li}, Xinyu and {Liu}, Chunhui and {Zolfaghari}, Mohammadreza and {Xiong}, Yuanjun and {Wu}, Chongruo and {Zhang}, Zhi and {Tighe}, Joseph and {Manmatha}, R. and {Li}, Mu},
        title = "{A Comprehensive Study of Deep Video Action Recognition}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Multimedia},
         year = 2020,
        month = dec,
          eid = {arXiv:2012.06567},
        pages = {arXiv:2012.06567},
          doi = {10.48550/arXiv.2012.06567},
archivePrefix = {arXiv},
       eprint = {2012.06567},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv201206567Z},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{breakfasts-dataset,
   author= {Kuehne, H. and Arslan, A. B. and Serre, T.},
   title = {The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities},
   booktitle = {Proceedings of Computer Vision and Pattern Recognition Conference (CVPR)},
   year = {2014},
}

@misc{50-salads-dataset,
  author       = {McKenna, S. and Stein, S.},
  title        = {50 Salads},
  year         = {2012},
  note         = {Creator},
  institution  = {University of Dundee},
  howpublished = {\url{https://doi.org/10.15132/10000120}}
}

@article{action-clip,
       author = {{Wang}, Mengmeng and {Xing}, Jiazheng and {Liu}, Yong},
        title = "{ActionCLIP: A New Paradigm for Video Action Recognition}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2021,
        month = sep,
          eid = {arXiv:2109.08472},
        pages = {arXiv:2109.08472},
          doi = {10.48550/arXiv.2109.08472},
archivePrefix = {arXiv},
       eprint = {2109.08472},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv210908472W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{time-s-former,
    author  = {Gedas Bertasius and Heng Wang and Lorenzo Torresani},
    title = {Is Space-Time Attention All You Need for Video Understanding?},
    booktitle   = {Proceedings of the International Conference on Machine Learning (ICML)}, 
    month = {July},
    year = {2021}
}

@article{mvit,
  title     = {Multiscale Vision Transformers},
  author    = {Li, Yanghao and Fan, Haoqi and Yan, Zhicheng and Xiong, Bo and Mangalam, Karttikeya and Malik, Jitendra and Feichtenhofer, Christoph},
  journal   = {arXiv preprint arXiv:2104.11227},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.11227}
}

@article{handcrafted-features-1,
  author    = {Ivan Laptev},
  title     = {On Space-Time Interest Points},
  journal   = {International Journal of Computer Vision},
  volume    = {64},
  number    = {2},
  pages     = {107--123},
  year      = {2005},
  publisher = {Springer},
  doi       = {10.1007/s11263-005-1173-4},
  url       = {https://doi.org/10.1007/s11263-005-1173-4},
}

@inproceedings{handcrafted-features-2,
  author    = {Heng Wang and Cordelia Schmid},
  title     = {Action Recognition with Improved Trajectories},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages     = {2921--2928},
  year      = {2013},
  publisher = {IEEE},
  doi       = {10.1109/ICCV.2013.365},
  url       = {https://doi.org/10.1109/ICCV.2013.365},
}

@article{tsn,
       author = {{Wang}, Limin and {Xiong}, Yuanjun and {Wang}, Zhe and {Qiao}, Yu and {Lin}, Dahua and {Tang}, Xiaoou and {Van Gool}, Luc},
        title = "{Temporal Segment Networks: Towards Good Practices for Deep Action Recognition}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2016,
        month = aug,
          eid = {arXiv:1608.00859},
        pages = {arXiv:1608.00859},
          doi = {10.48550/arXiv.1608.00859},
archivePrefix = {arXiv},
       eprint = {1608.00859},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160800859W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{vit,
       author = {{Dosovitskiy}, Alexey and {Beyer}, Lucas and {Kolesnikov}, Alexander and {Weissenborn}, Dirk and {Zhai}, Xiaohua and {Unterthiner}, Thomas and {Dehghani}, Mostafa and {Minderer}, Matthias and {Heigold}, Georg and {Gelly}, Sylvain and {Uszkoreit}, Jakob and {Houlsby}, Neil},
        title = "{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = 2020,
        month = oct,
          eid = {arXiv:2010.11929},
        pages = {arXiv:2010.11929},
          doi = {10.48550/arXiv.2010.11929},
archivePrefix = {arXiv},
       eprint = {2010.11929},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv201011929D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{impact-of-temporal-subsampling,
  author={Scheidegger, F. and Cavigelli, L. and Schaffner, M. and Malossi, A. C. I. and Bekas, C. and Benini, L.},
  booktitle={2017 25th European Signal Processing Conference (EUSIPCO)}, 
  title={Impact of temporal subsampling on accuracy and performance in practical video classification}, 
  year={2017},
  volume={},
  number={},
  pages={996-1000},
  keywords={Training;Feature extraction;Video sequences;Artificial neural networks;Europe;Graphics processing units},
  doi={10.23919/EUSIPCO.2017.8081357}}
